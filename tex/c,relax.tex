% relaxometry

\section{Introduction}
\label{s,relax,intro}

This brief chapter
\footnote{%
	This chapter partially derives content
	from conference papers
	\cite{nataraj:14:rje,nataraj:14:mbe}.
}
describes methods
for QMRI parameter estimation
from statistical likelihood models.
The main purpose of this chapter
is to serve as a bridge 
between the background information
reviewed in Chapter~\ref{c,bkgrd}
and more novel ideas 
introduced in later chapters.
As such, 
we place emphasis here
on development of notation and terminology
over thorough validation.
As instructional examples,
we demonstrate likelihood-based parameter estimation
on simple problems
involving estimation 
of relaxation parameters $\To$ and $\Tt$,
applications
that Chapter~\ref{c,scn-dsgn} motivates and studies 
in much greater detail.

The remainder of this chapter 
is organized as follows.
Section~\ref{s,relax,meth}
introduces the notion of a QMRI scan profile,
describes a signal model for parameter estimation,
and formulates two likelihood-based estimators
using this model.
Section~\ref{s,relax,exp}
demonstrates these likelihood-based estimators
through simulation experiments
in two simple applications
where conventional estimators are available.
Section~\ref{s,relax,disc} 
discusses advantages and drawbacks 
of these two likelihood-based estimators.
Section~\ref{s,relax,conc} 
provides concluding remarks.

\section{Likelihood-Based Estimation in QMRI}
\label{s,relax,meth}
% signal model and construction of scan profile

\subsection{The QMRI Scan Profile}
\label{ss,relax,meth,prof}

After image reconstruction,
many MRI pulse sequences
useful for parameter estimation
produce at each voxel 
centered at position $\bmr$
a set of noisy voxel values 
$\set{y_1\pr,\dots,y_D\pr}$, 
each of which can be described
with the following general model:
\begin{align}
	y_d\pr = s_d\paren{\bmx\pr; \bmnu\pr, \bmp_d} + \epsilon_d\pr,
	\label{eq:relax,mod-scalar}
\end{align}
where 
$d \in \set{1,\dots,D}$. 
Here,
$\bmx\pr \in \complexes{L}$ 
collects $L$ \emph{latent} object parameters at $\bmr$;
$\bmnu\pr \in \complexes{K}$ 
collects $K$ \emph{known} object parameters at $\bmr$;
$s_d : \complexes{L} \times \complexes{K} \times \reals{A} \mapsto \complex$
is a (pulse-sequence dependent) function
that models the noiseless signal 
obtained from the $d$th dataset
using \emph{acquisition} parameter $\bmp_d \in \reals{A}$;
and $\epsilon_d \sim \cgauss{0}{\sigma_d^2}$ 
is assumed for simplicity 
\footnote{%
	Though the noise distribution 
	of $\bmk$-space raw data 
	is usually well-modeled
	as complex white Gaussian, 
	the noise distribution 
	of the $d$th reconstructed image $y_d$ depends both
	on the acquisition and reconstruction.
	If single receive channel $\bmk$-space data
	is fully-sampled
	on a Cartesian grid,
	each dataset $y_d$ is recoverable
	via separate Fourier transform,
	and is thus complex Gaussian
	and independent across datasets.
	However if $\bmk$-space data
	is multi-channel, undersampled, and/or non-Cartesian,
	it may be preferable
	that $y_d$ be estimated by more sophisticated techniques,
	\eg \cite{fessler:03:nff, muckley:15:fpm}.
	In such cases,
	reconstructed image noise is unlikely
	to be Gaussian-distributed.
}
to be (circularly-symmetric) complex Gaussian noise
\cite{macovski:96:nim, lei:07:som}
with zero mean and variance $\sigma_d^2$.
Semicolon positions 
in signal model \eqref{eq:relax,mod-scalar} 
and similar expressions throughout this thesis 
distinguish unknown and known parameters.
Concrete examples follow shortly.

For accurate, well-conditioned QMRI parameter estimation,
it is typically necessary 
to acquire a collection of datasets,
which we refer to hereafter as a \emph{scan profile}.
A scan profile consists 
of $D$ datasets
from up to $D$ pulse sequences
(some sequences yield more than one dataset, \eg, DESS).
Let 
$\bmy\pr := \brac{y_1\pr, \dots, y_D\pr}\tpose \in \complexes{D}$
collect noisy voxel values centered at $\bmr$
from a given scan profile.
Then the vector signal model
\begin{align}
	\bmy\pr = \bms\paren{\bmx\pr; \bmnu\pr, \bmP} + \bmeps\pr
	\label{eq:relax,mod-vec}
\end{align}
helps define the noiseless signal 
$\bms := \brac{s_1, \dots, s_D}\tpose
: \complexes{L} \times \complexes{K} \times \reals{A \times D} \mapsto \complexes{D}$
and acquisition parameters
$\bmP := \brac{\bmp_1,\dots,\bmp_D} \in \reals{A \times D}$
associated with that scan profile.
Here, noise
$\bmeps\pr := \brac{\epsilon_1\pr, \dots, \epsilon_D\pr}\tpose \in \complexes{D}$
typically has diagonal covariance structure
$\bmSig := \diag{\brac{\sigma_1,\dots,\sigma_D}\tpose}$
due to independence across datasets,
where $\diag{\cdot}$ assigns its argument 
to the diagonal entries 
of an otherwise zero (square) matrix.

The following subsections
describe two concrete scan profiles
whose signals can be modeled 
via \eqref{eq:relax,mod-vec} 
and that we study through experiments
later in this chapter.

\subsubsection{Example: An SPGR Scan Profile for $\To$ estimation}
\label{sss,relax,meth,prof,t1}

We first consider the problem
of $\To\pr$ estimation at $\bmr$ 
from as few SPGR scans as possible,
given a prior estimate
of transmit field variation $\stx\pr$
(see \eqref{eq:flip-def}).
Examining SPGR model \eqref{eq:spgr-model}
makes clear that 
by fixing echo time $\TE$ across scans, 
SPGR signal dependence is reduced 
to just two spatially varying latent parameters:
desired parameter $\To\pr \in \real$ and 
nuisance parameter 
$\const{1}\pr := i\mzero\pr e^{-\TE/\Tts\pr} e^{-i\ompmed\pr \TE} \in \complex$.
We assign $\bmx \gets \brac{\To, \const{1}}\tpose$ and $\bmnu \gets \stx$
for $L \gets 2$ latent 
and $K \gets 1$ known parameters, respectively.

With $\TE$ fixed, 
prescribed flip angles $\flipnom$ 
and repetition times $\TR$ 
are the only remaining $A \gets 2$ 
acquisition parameters
available to choose
that appear explicitly in \eqref{eq:spgr-model}.
Thus, an SPGR scan profile 
useful for $\To$ estimation 
must vary 
$\bmp_d \gets \brac{\flipnom, \TR}\tpose
\forall d \in \set{1,\dots,D}$
over $\Ss$ scan repetitions
to produce $D \geq L \gets 2$ datasets
for well-conditioned estimation.

\subsubsection{Example: A DESS Scan Profile for $\Tt$ estimation}
\label{sss,relax,meth,prof,t2}

We next consider 
the problem of $\Tt\pr$ estimation at $\bmr$
from as few DESS scans as possible.
Examining DESS models 
\eqref{eq:dess-def-model} and \eqref{eq:dess-ref-model}
makes clear that even with fixed $\TE$
over possibly several acquisitions, 
there is signal dependence 
on five distinct object parameters:
$\stx\pr \in \real$,
$\To\pr \in \real$, 
$\ompmed\pr \in \real$,
$\const{2}\pr := \mzero\pr e^{-\TE/\Tts\pr} \in \complex$, 
and $\Tt\pr \in \real$.
In this chapter,
we take $\stx\pr \in \real$ and $\To\pr \in \real$
as known for simplicity.
To avoid (separate or joint) $\ompmed\pr$ estimation,
we choose to use magnitude DESS data,
at the expense of slight model mismatch
\footnote{The assumption of complex Gaussian noise 
in noisy MRI images
implies that corresponding magnitude MRI images
are Rician-distributed.
However,
the statistical estimators
we will develop
in Subsection~\ref{ss,relax,meth,est}
are based on Gaussian data.
Fortunately,
this source of model mismatch
is negligible (less than $1\%$)
for signal-to-noise ratio (SNR)
in excess of 10 \cite{gudbjartsson:95:trd},
and the acquisitions we examine here
are capable of producing SNR in tissue 
of at minimum $100$ and usually more. 
}
due to Rician noise.
These choices assign 
$\bmnu \gets \brac{\stx, \To}\tpose$ 
as $K \gets 2$
known parameters
and leave $L \gets 2$
latent parameters  
$\bmx \gets \brac{\Tt, \const{2}}\tpose$
to be estimated.

With $\TE$ again fixed, 
$\bmp_d \gets \brac{\flipnom, \TR}\tpose
\forall d \in \set{1,\dots,D}$
collects the remaining $A \gets 2$ 
tunable scan parameters
that appear explicitly in
\eqref{eq:dess-def-model} and \eqref{eq:dess-ref-model}.
As in Example~\ref{sss,relax,meth,prof,t1},
$D \geq L \gets 2$ datasets are necessary
for well-conditioned estimation.
Unlike before however,
a minimum $D \gets 2$ datasets 
need not require scan repetition,
since $\Sd$ DESS scan repetitions
produce $D \gets 2\Sd$ datasets.

\subsection{Latent Object Parameter Estimation}
\label{ss,relax,meth,est}

\subsubsection{Signal Model and Problem Statement}
\label{sss,relax,meth,est,sig}

A scan profile's reconstructed images
can be modeled 
to discretize the bulk MR signal 
into $V$ localized voxels
centered at positions $\bmr_1,\dots,\bmr_V$:
\begin{align}
	\bmY = \bmS\paren{\bmX; \bmN, \bmP} + \bmE.
	\label{eq:relax,mod-mtx}
\end{align}
Here, signal model
$\bmS : \complexes{L\times V} \times \complexes{K\times V}
\times \reals{A \times D} \mapsto \complexes{D \times V}$ 
is a matrix function
that maps latent 
$\bmX := \brac{\bmx\paren{\bmr_1},\dots,\bmx\paren{\bmr_V}} 
\in \complexes{L\times V}$
and known 
$\bmN := \brac{\bmnu\paren{\bmr_1},\dots,\bmnu\paren{\bmr_V}} 
\in \complexes{K\times V}$
parameter images 
(with fixed acquisition parameter $\bmP$)
to reconstructed image data
$\bmY := \brac{\bmy\paren{\bmr_1},\dots,\bmy\paren{\bmr_V}} 
\in \complexes{D\times V}$,
save for noise image
$\bmE := \brac{\bmeps\paren{\bmr_1},\dots,\bmeps\paren{\bmr_V}} 
\in \complexes{D\times V}$. 
The goal in QMRI parameter estimation
is to estimate latent parameter images $\bmX$ 
from MR image data $\bmY$,
for a fixed scan profile defined by $\bmS$ and $\bmP$
and given (separately acquired, estimated, and here assumed)
known parameter images $\bmN$.

\subsubsection{Maximum Likelihood Methods}
\label{sss,relax,meth,est,ml}
% from likelihood function to...
% ml cost

In maximum likelihood (ML) estimation,
one seeks model parameters
that maximize the likelihood
of observing output data.
We apply ML estimation to QMRI
by first constructing 
a \emph{likelihood function}
that describes the probability 
of observing image data $\bmY$
given latent parameters $\bmX$.
We then formulate 
ML latent parameter estimator $\estML{\bmX}$
by finding an estimate $\estaML{\bmX}{\bmY; \bmN, \bmP}$ 
of $\bmX$
that maximizes this likelihood function. 

We first construct the likelihood function
for the $v$th voxel's data $\bmy\paren{\bmr_v}$ 
and latent parameter $\bmx\paren{\bmr_v}$.
For complex Gaussian noise,
the likelihood function is
\begin{align}
	\Lf{\bmx\paren{\bmr_v}} \propto
	\expa{-\norm{\bmy\paren{\bmr_v}-
	\bms\paren{\bmx\paren{\bmr_v}; \bmnu\paren{\bmr_v}, \bmP}}^2_{\bmSig^{-1}}},
	\label{eq:relax,lf-vec}
\end{align}
where \eqref{eq:relax,lf-vec} omits constants
that are independent of $\bmx\paren{\bmr_v}$
and are therefore irrelevant.
Assuming noise independence 
across image voxels,
we can next build 
a simple and practical likelihood function
of the full image data as
\begin{align}
	\Lf{\bmX} &= \prod_{v=1}^V \Lf{\bmx\paren{\bmr_v}}.
	\label{eq:relax,lf-mtx}
\end{align}
We form an ML parameter estimate
by finding $\bmX$  
that maximizes this likelihood function:
\begin{align}
	\estaML{\bmX}{\bmY; \bmN, \bmP} &\in \set{\argmax{\bmX \in \setX^V} \Lf{\bmX}} 
	\nonumber \\
	&\equiv \set{\argmin{\bmX \in \setX^V} -\log{\Lf{\bmX}}}
	\label{eq:relax,ml-log-lf} \\
	&= \set{\argmin{\bmX \in \setX^V} 
	\sum_{v=1}^V \norm{\bmy\paren{\bmr_v} -
	\bms\paren{\bmx\paren{\bmr_v}; \bmnu\paren{\bmr_v}, \bmP}}^2_{\bmSig^{-1}}}
	\nonumber \\
	&= \set{\argmin{\bmX \in \setX^V} 
	\frob{\bmSig^{-1/2} \paren{\bmY - \bmS\paren{\bmX; \bmN, \bmP}}}^2},
	\label{eq:relax,ml-est}
\end{align}
where $\setX$ is a (typically convex) latent parameter search space;
the set equivalence in \eqref{eq:relax,ml-log-lf} 
uses the monotonicity of the $\log$ function;
and $\frob{\cdot}$ denotes the Frobenius matrix norm.

Typically, 
QMR image model $\bmS$ is nonlinear in $\bmX$
and so ML estimation problem \eqref{eq:relax,ml-est}
involves non-convex optimization,
which is challenging in general
(see Section~\ref{s,bkgrd,opt}).
Two properties 
of \eqref{eq:relax,ml-est}
guide our solution strategies.
First, 
\eqref{eq:relax,ml-est} is separable across voxels,
so problem non-convexity is addressable 
on a voxel-by-voxel basis.
Second,
MR signal models are usually partially linear,
in which case we may employ the variable projection method 
(described in Section~\ref{ss,bkgrd,opt,vpm})
to further reduce problem complexity.
For applications studied
in this chapter,
these properties allow for \eqref{eq:relax,ml-est}
to be solved via simple grid search.
 
\subsubsection{Regularized Likelihood Methods}
\label{sss,relax,meth,est,rls}
% rls cost 
% regularizers one might use

In regularized likelihood (RL) estimation,
we modify ML estimation problem \eqref{eq:relax,ml-log-lf}
to include additional information
in the form of \emph{regularization}:
\begin{align}
	\estaRL{\bmX}{\bmY; \bmN, \bmP} &\in
	\set{\argmin{\bmX \in \setX^V} -\log{\Lf{\bmX}} + \Rega{\bmX}}.
	\label{eq:relax,rl-est}
\end{align}
Here,
we have freedom to design regularizer 
$\Reg : \complexes{L \times V} \mapsto \real$ 
to encourage desirable structure
in estimates of $\bmX$. 
We observe
that it is usually reasonable
to assume that each latent object parameter map
is \emph{piecewise smooth} as a function of space:
that is, 
each parameter is likely 
to vary smoothly in space,
except for sharp discontinuities 
at tissue boundaries.
To encourage piecewise-smoothness 
in parameter estimates,
we use the regularizer 
\begin{align}
	\Rega{\bmX} &:= \sum_{l=1}^L \beta_l \sum_{j=1}^J
	\phi_l\paren{\brac{\bmJ\bmX\tpose}_{jl}}, \where
	\label{eq:relax,reg} \\
	\phi_l\paren{\cdot} &:= 
	\gamma_l^2 \paren{\sqrt{1 + \abs{\cdot/\gamma_l}^2} - 1}
\end{align}
is a differentiable approximation
of the absolute value function;
$\bmJ \in \reals{J\times V}$ 
evaluates $J$ (multi-dimensional) finite-differencing operations;
$\brac{\cdot}_{jl}$ extracts the $\paren{j,l}$th matrix element;
and $\beta_l$ is a regularization parameter
that controls the relative importance
of smoothing the $l$th latent object parameter image.
Conceptually,
this regularizer penalizes inconsistencies 
in adjacent latent parameter image voxels,
but with a severity that depends
on the degree of inconsistency. 
``Small'' voxel-to-voxel differences 
are likely due to image data noise
within a single tissue type
and are penalized near-quadratically, 
while ``large'' differences
are likely due to tissue boundaries
and are penalized near-linearly.
Useful notions 
of small versus large differences
are governed by shape parameters 
$\gamma_l\, \forall l\in\set{1,\dots,L}$,
and vary for different latent parameter maps
based on their units and relative scale.

In general, 
QMRI image signal model $\bmS$ is nonlinear in $\bmX$
and so RL estimation problem \eqref{eq:relax,rl-est}
requires non-convex optimization.
Unlike in ML estimation,
\eqref{eq:relax,rl-est} is not separable across voxels
due to regularization, 
precluding global optimization
(via grid search or other methods).
We instead take the corresponding ML estimate
as initialization
and solve \eqref{eq:relax,rl-est} 
via iterative constrained local optimization
(detailed in Section~\ref{ss,bkgrd,opt,loc}).

%\subsection{Practical Considerations}
%\label{ss,relax,meth,pract}
% preconditioner design

\section{Experimentation}
\label{s,relax,exp}
% experiments and results

This section demonstrates likelihood-based estimation
through two experiments in simulation
that correspond to the simple problems defined
in Section~\ref{ss,relax,meth,prof}.
Subsection~\ref{ss,relax,exp,t1} continues Example~\ref{sss,relax,meth,prof,t1}
in studying $\To$ estimation
from two SPGR scans.
Subsection~\ref{ss,relax,exp,t2} continues Example~\ref{sss,relax,meth,prof,t2}
in studying $\Tt$ estimation
from one DESS scan.

\subsection{$\To$ estimation from two SPGR scans}
\label{ss,relax,exp,t1}
% t1 estimation from spgr

We selected $\To$ and $\Tt$ WM and GM values
based on previously reported measurements at 3T 
\cite{wansapura:99:nrt, stanisz:05:ttr}
and extrapolated other nuisance latent object parameters
$\mzero$ and $\Tts$
from measurements at 1.5T \cite{kwan:99:msb}.
For simplicity,
we assumed no flip angle variation $\stx \gets 1$ 
and no phase accrual due to off-resonance effects $\ompmed \gets 0$.
We assigned these parameter values
to the 81st slice
of the BrainWeb digital phantom
\cite{collins:98:dac, kwan:99:msb}
to create ground truth $\bmMz, \bmTo, \bmTt, \bmTts \in \reals{V}$ maps.
We simulated $217 \times 181$
noiseless single-coil SPGR image datasets,
varying nominal flip angles $\flipnom \gets \degrees{5,30}$
and fixing repetition times $\TR \gets 12.2$ms 
and echo times $\TE \gets 4.67$ms across $\Ss \gets 2$ scans.
We corrupted noiseless datasets
with additive complex Gaussian noise
to yield $D \gets 2$ noisy complex datasets
with signal-to-noise ratio (SNR) ranging from 57-93,
where SNR is defined here as
\begin{align}
	\snr{\bmS,\bmY} := \frac{\frob{\bmS}}{\frob{\bmY-\bmS}}.
	\label{eq:relax,snr}
\end{align}

We estimated latent parameter maps $\bmTo,\Const{1}$ 
using a conventional method-of-moments (MOM) estimator \cite{gupta:77:anl},
the ML estimator \eqref{eq:relax,ml-est}, 
and the RL estimator \eqref{eq:relax,rl-est}.
The MOM, ML, and RL estimators 
respectively took $0.11$s, $0.75$s, and $31$s. 
The MOM estimator applies linear regression voxel-by-voxel
to an appropriately transformed version
of the noiseless magnitude SPGR signal model
that is linear in $\To,\const{1}$;
see \eg \cite{gupta:77:anl,deoni:03:rct} for details.
We next describe our implementations 
of ML and RL estimation in turn.

The ML estimator applies the variable projection method
(VPM; described in Subsection~\ref{ss,bkgrd,opt,vpm})
to separate nonlinear $\bmTo$ estimation 
from linear $\Const{1}$ estimation.
Specifically,
the algorithm first estimates $\bmTo$ voxel-by-voxel
via an exhaustive grid search 
(over $1000$ $\To$ values
logarithmically spaced between $(10^{1.5}, 10^{3.5})$ms)
for a maximizer
of the separated least squares cost \eqref{eq:sep-ls-nonlin}.
It then estimates $\Const{1}$ 
via per-voxel linear regression.

The RL estimator applies a preconditioned variant
of the classical gradient projection method 
(GPM; described in Subsection~\ref{ss,bkgrd,opt,loc})
to iteratively descend 
towards a local optimizer 
of the RL cost
described in \eqref{eq:relax,rl-est}.
We designed the preconditioner
as the inverse
of a positive definite diagonal majorizer
of the RL cost function's Hessian matrix,
updated for the first five iterations
and fixed thereafter.
We employed a diagonal preconditioner
to retain the linear convergence guarantees
of GPM \cite{bertsekas:82:pnm}
yet approach the practical performance
of other unprojected second-order methods
(\eg, Newton's method).
We employed a simple step-halving line search
at each iteration
to ensure monotone local convergence in cost.
We initialized GPM 
with the ML estimates.
We selected regularization parameters
as described in Subsection~\ref{sss,scn-dsgn,exp,phant,roi}.
We used the Michigan image reconstruction toolbox \cite{fessler:16:irt}
to construct the regularizer
and rapidly evaluate its gradient and Hessian.
We used the \matlab symbolic toolbox
to generate analytical expressions
for the gradient and Hessian 
of the SPGR signal model.
At each iteration,
we used these gradient and Hessian expressions
to compute a preconditioned descent direction,
updated the iterate
(possibly after backtracking to ensure descent),
and projected each voxel's $\To$ iterate
to within $\brac{10,3000}$ms.
We continued iterations
until the convergence criterion
\begin{align}
   \frob{\bmOmega^{-1}\paren{\iter{\bmX}{i}-\iter{\bmX}{i-1}}} 
   		< 10^{-7} \frob{\bmOmega^{-1}\paren{\iter{\bmX}{i}}}
   \label{eq:relax,conv-crit}
\end{align}
was satisfied,
where $\iter{\paren{\cdot}}{i}$ denotes the $i$th iterate,
$\bmOmega := \diag{\med{\iter{\bmX}{0}}}$
is a weighting matrix,
and $\med{\cdot}$ takes the median 
across the columns of its argument.

\begin{figure}[!t]
	\centering
	\subfigure{%
		\includegraphics [width=15.4cm] {%
			sp2de0,sl-81,t1,im,jet.eps%
		}
		\label{fig:relax,sim,t1,im,jet}
	}
	\hspace{0cm}
	\subfigure{%
		\includegraphics [width=15.2cm,trim=0 0 0 25,clip] {%
			sp2de0,sl-81,t1,err,jet.eps%
		}
		\label{fig:relax,sim,t1,err,jet}
	}
	\caption{%
		$\bmTo$ MOM, ML, and RL estimates
		and corresponding error images,
		from two simulated SPGR scans.
		Magnitude error images are $10\times$ magnified.
		Voxels not assigned WM- or GM-like relaxation times
		are masked out in post-processing for display.
		Table~\ref{tab:relax,sim,t1} 
		presents corresponding sample statistics.
	}
	\label{fig:relax,sim,t1}
\end{figure}

Fig.~\ref{fig:relax,sim,t1} compares 
MOM, ML, and RL $\bmTo$ estimates
alongside $10\times$ magnified absolute difference images
with respect to the ground truth.
Overall, 
all three estimators produce reasonable $\bmTo$ maps.
The MOM and ML $\bmTo$ estimates are visually similar.
The RL $\bmTo$ estimates are smoother
than the MOM and ML $\bmTo$ estimates
away from tissue interfaces,
but the RL $\bmTo$ estimate 
incurs systematically higher errors
near tissue boundaries
and provides reduced spatial resolution.

\begin{table}[!t]
	\small
	\centering
	\begin{tabular}{c | r | r r r}
		\hline
		\hline
										& Truth 	& MOM 										& ML 												& RL \\
		\hline
		WM $\To$ 				& $832$		& \mnstd{832.7}{15.6} 		& \mnstd{832.7}{15.6} 			& \mnstd{834.00}{2.77} \\
		GM $\To$ 				& $1331$ 	& \mnstd{1332}{34.9} 			& \mnstd{1332}{34.9} 				& \mnstd{1332.2}{6.3} \\
		\hline
		WM $\const{1}$ 	& $0.77$ 	& \mnstd{0.7266}{0.00744}	& \mnstd{0.7314}{0.00749} 	& \mnstd{0.73184}{0.00475} \\
		GM $\const{1}$ 	& $0.86$ 	& \mnstd{0.8245}{0.0108} 	& \mnstd{0.8301}{0.0109} 		& \mnstd{0.8287}{0.0059} \\
		\hline
		\hline
	\end{tabular}
	\caption{%
		Sample means $\pm$ sample standard deviations
		of MOM, ML, and RL $\To,\const{1}$ estimates
		from two simulated SPGR datasets,
		computed over $3001$ WM-like and $1151$ GM-like voxels.
		Each sample statistic is rounded off
		to the highest place value
		of its (unreported) standard error,
		computed via formulas in \cite{ahn:03:seo}.
		$\To$ values are in milliseconds.
		$\const{1}$ values are unitless.
		Fig.~\ref{fig:relax,sim,t1} 
		presents corresponding images.
	}
	\label{tab:relax,sim,t1}
\end{table}

Table~\ref{tab:relax,sim,t1} presents
$\To,\const{1}$ samples statistics
within WM-like and GM-like ROIs
selected to contain voxels
that are well away from tissue interfaces. 
In both WM and GM,
MOM and ML $\bmTo,\Const{1}$ estimates are comparable.
RL estimates consistently exhibit
the lowest variation,
but the RL $\bmTo$ estimate
exhibits the greatest bias in WM.
All RL bias values would be significantly greater
if ROIs instead contained voxels at tissue interfaces.

\subsection{$\Tt$ estimation from one DESS scan}
\label{ss,relax,exp,t2}
% t2 estimation from dess

Using the same ground truth parameters maps
as in Subsection~\ref{ss,relax,exp,t1},
we simulated noiseless single-coil DESS image datasets
arising from $\Sd \gets 1$ DESS scan
with nominal flip angle $\flipnom \gets \degrees{45}$,
repetition time $\TR \gets 17.5$ms,
and symmetric echo times $\TE \gets 4.67$ms.
We corrupted noiseless datasets
with additive complex Gaussian noise 
to yield $D \gets 2$ noisy complex datasets
with SNR ranging from 97-134,
where SNR is defined as in \eqref{eq:relax,snr}.

We estimated latent parameter maps $\bmTt, \Const{2}$ 
using a conventional MOM estimator \cite{bruder:88:ans},
the ML estimator \eqref{eq:relax,ml-est},
and the RL estimator \eqref{eq:relax,rl-est}.
The MOM, ML, and RL estimators 
respectively took $0.09$s, $0.76$s, and $26$s;
we describe their implementations next in turn.
For symmetric echo times,
the voxel-by-voxel MOM estimator assigns
\begin{align}
	\est{T}_2\paren{y_1,y_2} \gets -\frac{2\paren{\TR-\TE}}{\log{\abs{y_2/y_1}}},
	\label{eq:relax,dess,mom}
\end{align}
where $y_1$ and $y_2$ are noisy measurements
of the defocused \eqref{eq:dess-def-model}
and refocused \eqref{eq:dess-ref-model} DESS signals,
respectively.
With $\est{\mathbf{T}}_2$ fixed,
the MOM method then estimates $\Const{2}$ 
via per-voxel linear regression.
This MOM estimator incurs strong bias
for flip angles 
that provide practical SNR levels,
mainly because it neglects $\To$ effects.
This MOM estimator also amplifies noise 
due to the division operation.

Similar to Subsection~\ref{ss,relax,exp,t1},
the ML estimator applies VPM
to separate nonlinear $\bmTt$ estimation
from linear $\Const{2}$ estimation.
The algorithm first estimates $\bmTt$ voxel-by-voxel
via an exhaustive grid search
over 1000 $\Tt$ values
logarithmically spaced between $\paren{10^{0.5},10^3}$ms.
It then estimates $\Const{2}$ 
via per-voxel linear regression.

The RL estimator applies preconditioned GPM
to iteratively descend towards a local optimizer
of the RL cost 
described in \eqref{eq:relax,rl-est}.
GPM implementation details
remain largely unchanged 
from those described 
in Subsection~\ref{ss,relax,exp,t1}.
At each iteration,
we computed a preconditioned descent direction
(using \matlab-generated analytical expressions
for the gradient and Hessian
of the DESS signal models),
updated the iterate
(possibly after backtracking 
to ensure monotone descent),
and projected each voxel's $\Tt$ iterate
to within $\brac{1,700}$ms.
We continued iterations
until convergence criterion \eqref{eq:relax,conv-crit}
was satisfied.

\begin{figure}[!t]
	\centering
	\subfigure{%
		\includegraphics [width=15.4cm] {%
			sp0de1,sl-81,t2,im,jet.eps%
		}
		\label{fig:relax,sim,t2,im,jet}
	}
	\hspace{0cm}
	\subfigure{%
		\includegraphics [width=15.2cm,trim=0 0 0 25,clip] {%
			sp0de1,sl-81,t2,err,jet.eps%
		}
		\label{fig:relax,sim,t2,err,jet}
	}
	\caption{%
		$\bmTt$ MOM, ML, and RL estimates
		and corresponding error images,
		from one simulated DESS scan.
		Magnitude error images are $10\times$ magnified.
		Voxels not assigned WM- or GM-like relaxation times
		are masked out in post-processing for display.
		Table~\ref{tab:relax,sim,t2} 
		presents corresponding sample statistics.
	}
	\label{fig:relax,sim,t2}
\end{figure}

Fig.~\ref{fig:relax,sim,t2} compares
MOM, ML, and RL $\bmTt$ estimates
alongside $10\times$ magnified absolute difference images 
with respect to the ground truth.
Overall, 
the ML and RL estimators 
produce more reasonable $\bmTt$ maps
than does the MOM estimator
(but utilize additional $\stx,\To$ information).
The RL $\bmTt$ estimates are smoother
than ML $\bmTt$ estimates 
away from tissue interfaces,
but the RL $\bmTt$ estimate incurs 
systematically higher errors 
near tissue boundaries
and provides reduced spatial resolution.

\begin{table}[!t]
	\small
	\centering
	\begin{tabular}{c | r | r r r}
		\hline
		\hline
										& Truth 	& MOM 										& ML 												& RL \\
		\hline
		WM $\Tt$ 				& $79.6$ 	& \mnstd{68.13}{1.64} 		& \mnstd{79.36}{2.18} 			& \mnstd{76.402}{0.411} \\
		GM $\Tt$ 				& $110.$ 	& \mnstd{95.86}{3.21}			& \mnstd{110.2}{4.19} 			& \mnstd{111.57}{0.88} \\
		\hline
		WM $\const{2}$ 	& $0.77$ 	& \mnstd{0.8578}{0.0148}	& \mnstd{0.7852}{0.0149} 		& \mnstd{0.79290}{0.00457} \\
		GM $\const{2}$ 	& $0.86$ 	& \mnstd{0.9523}{0.0241} 	& \mnstd{0.8545}{0.0240} 		& \mnstd{0.8510}{0.0063} \\
		\hline
		\hline
	\end{tabular}
	\caption{%
		Sample means $\pm$ sample standard deviations
		of MOM, ML, and RL $\Tt,\const{2}$ estimates
		from one simulated DESS dataset,
		computed over $3001$ WM-like and $1151$ GM-like voxels.
		Each sample statistic is rounded off
		to the highest place value
		of its (unreported) standard error,
		computed via formulas in \cite{ahn:03:seo}.
		$\Tt$ values are in milliseconds.
		$\const{2}$ values are unitless.
		Fig.~\ref{fig:relax,sim,t2} 
		presents corresponding images.
	}
	\label{tab:relax,sim,t2}
\end{table}

Table~\ref{tab:relax,sim,t2} presents 
$\Tt,\const{2}$ sample statistics
within the same well-isolated ROIs
as was used in Table~\ref{tab:relax,sim,t1}.
MOM estimates are consistently most biased.
The MOM and ML $\bmTt$ estimates
exhibit similar levels of variability.
RL estimates consistently exhibit
more bias and less variation
than ML estimates.

\section{Discussion}
\label{s,relax,disc}

% result summary
% ml and rl estimators often better than mom
% 	ex 1: small accuracy gains in c1 due to consideration of complex data
% 	ex 2: much larger gains in c2/t2 by avoiding bias-inducing assumptions for closed-form expressions (though avoiding these assumptions either requires prior knowledge as here or joint estimation which can reduce precision)
% 	both examples: consider noise statistics
% 	both examples: regularization increases precision but introduces edge effects
% however often require greater computation
The simulated experiments in this chapter
serve to illustrate
that MRI parameter estimation
from likelihood models  
can often offer greater accuracy
than conventional MOM estimation,
though usually at the expense 
of greater computation.
Simulations corresponding to Ex.~\ref{sss,relax,meth,prof,t1}
demonstrated small but consistent ML and RL accuracy gains 
over MOM $\const{1}$ estimation,
primarily because likelihood-based estimators 
here considered complex image noise statistics.
Simulations corresponding to Ex.~\ref{sss,relax,meth,prof,t2}
demonstrated larger ML and RL accuracy gains
over MOM $\Tt,\const{2}$ estimation,
primarily because likelihood-based estimators
here required fewer bias-inducing signal model approximations.
In general,
such accuracy gains
may be more substantial
in more complicated QMRI estimation problems
that for MOM estimation 
will require stronger model approximations.

%	ml and rl methods are more general
% can often be used in more complicated problems where mom estimator unavailable
% this is reason we focus on ml and rl in later chapters
Because likelihood-based estimators do not rely 
on (possibly intractable) algebraic manipulations 
of the application-specific signal model,
they are also more general-purpose tools 
than are MOM estimators.
Indeed, 
algorithms for implementing the ML \eqref{eq:relax,ml-est}
(\ie, VPM with grid search)
or RL \eqref{eq:relax,rl-est} estimators
(\ie, GPM)
are typically available
even when the associated inverse problem
is poorly conditioned.
In such cases,
ML estimates still need not necessarily be imprecise
in all latent parameter entries,
a behavior that Ch.~\ref{c,scn-dsgn}
characterizes and then exploits.
Because of their relative flexibility,
we utilize likelihood-based estimators
over MOM estimators
for the more complex QMRI problems
studied in Ch.~\ref{c,scn-dsgn}.

% ml and rl have bias-variance tradeoff
% ml may be better when fully-sampled in qmri since accuracy important
% rl has many tuning parameters (2L with this regularizer)
% since this thesis uses fully-sampled data, will not emphasize spatial reg
% however it is used in chapter 4
Simulations herein demonstrate
that ML versus RL estimation performance
can be characterized by a bias-variance tradeoff: 
RL estimation reduces variation 
in regions well away from tissue interfaces,
but increases bias near interfaces.
Thus, 
a decision of whether to include regularization 
(and with what strength)
should consider the degree 
to which regions of interest contain interfaces.
Since the applications studied in later chapters
take interest in resolving subtle WM/GM boundaries 
with high spatial resolution
and associated experiments use fully-sampled $\bmk$-space data,
we hereafter employ ML estimation by default
(though Ch.~\ref{c,scn-dsgn} also provides comparisons with RL estimation).
In other QMRI problems
that utilize low spatial frequency or highly under-sampled data
or involve poorly-conditioned parameter estimation,
including regularization may instead be preferable.

% here used acquisition parameters similar to those used in earlier works
% call into question this somewhat arbitrary choice
% chapter 4 provides more principled way to choose these
Both simulated experiments
used acquisition parameters
similar to those used 
in earlier studies \cite{deoni:03:rct,heule:14:reo}.
While these studies provide intuitive reasoning
for some acquisition parameter choices,
it is unclear 
whether these choices are
in any sense optimal
for the respective tasks of $\To$ or $\Tt$ estimation.
Motivated by this question,
Ch.~\ref{c,scn-dsgn} defines one notion
of acquisition parameter optimality
and investigates how optimized acquisition parameters
can improve $\To,\Tt$ ML estimation performance.

\section{Conclusion}
\label{s,relax,conc}

This transitional chapter 
has developed a formalism
to describe a general QMRI scan profile
and has described two likelihood-based estimators
for QMRI parameter estimation.
We have demonstrated these ML and RL estimators
in two simple applications
where conventional MOM estimators are available,
namely $\To$ estimation from two SPGR scans
and $\Tt$ estimation from one DESS scan.
Simulations illustrate 
that ML and RL estimators
can often offer greater accuracy
than MOM estimators,
though usually at the expense
of greater computation.
Because of their accuracy and generality,
likelihood-based QMRI estimators
will be used 
to validate a new method for scan design
in Ch.~\ref{c,scn-dsgn}
and for comparison 
with a new QMRI parameter estimation method
in Ch.~\ref{c,perk}.
